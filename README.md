# WebCrawler
仿scrapy的爬虫框架 (python3.5以上模块化,需要支持async/await语法)
看说明文件
spiders下是例子

redis目前只用到了错误url记录，也可以作为队列，未爬取，已爬取，错误
mongodb储存结构化数据

系统有重试机制，日志，邮件警报等
